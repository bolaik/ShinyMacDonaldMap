length(cooks.distance(fit))
dffits(fit)[1:10]
dfbeta(fit)[1:10, 1]
dfbeta(fit)[1:10, ]
cooks.distance(fit)[1:10]
?cooks.distance
plot(predict(fit), rstudent(fit))
x <- c(10, rnorm(n)); y <- c(10, c(rnorm(n)))
# plot y vs x
plot(x, y, frame = FALSE, cex = 1, pch = 21, bg = "lightblue", col = "black")
# perform linear regression
fit <- lm(y ~ x)
# add regression line to plot
abline(fit)
plot(predict(fit), rstudent(fit))
# load swiss data and
data(swiss)
# run linear regression on Fertility vs all other predictors
fit <- lm(Fertility ~ . , data = swiss)
# generate diagnostic plots in 2 x 2 panels
par(mfrow = c(2, 2)); plot(fit)
plot(predict(fit), rstudent(fit))
plot(predict(fit), resid(fit)/(1 - hatvalues(fit)))
dim(dfbeta(fit))
plot(predict(fit), dfbeta(fit)[,2])
plot(predict(fit), dfbeta(fit)[,6])
plot(predict(fit), hatvalues(fit))
x <- c(10, rnorm(n)); y <- c(10, c(rnorm(n)))
# plot y vs x
plot(x, y, frame = FALSE, cex = 1, pch = 21, bg = "lightblue", col = "black")
# perform linear regression
fit <- lm(y ~ x)
# add regression line to plot
abline(fit)
plot(predict(fit), hatvalues(fit))
plot(predict(fit), dfbeta(fit)[,2])
x <- rnorm(n); y <- x + rnorm(n, sd = .3)
# add an outlier that fits the relationship
x <- c(5, x); y <- c(5, y)
# plot the (x, y) pairs
plot(x, y, frame = FALSE, cex = 1, pch = 21, bg = "lightblue", col = "black")
# perform the linear regression
fit2 <- lm(y ~ x)
# add the regression line to the plot
abline(fit2)
plot(predict(fit), hatvalues(fit2))
plot(predict(fit), dfbeta(fit2)[,2])
plot(predict(fit), dfbeta(fit2)[,1])
library(car)
install.packages(car)
install.packages("car")
library(car)
data(swiss)
fit <- lm(Fertility ~ ., data = swiss)
vif(fit)
head(swiss)
q()
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
installed.packages("caret")
install.packages("carett")
install.packages("caret")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
install.packages("AppliedPredictiveModeling")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
train_sub <- training[[grepl("^IL", names(training))]]
train_sub <- training[[grep("^IL", names(training))]]
train_sub <- training[,grep("^IL", names(training))]
names(train_sub)
?prcomp
prcomp(train_sub)
plot(prcomp(train_sub))
names(prcomp(train_sub))
prcomp(train_sub)$sdev
pca <- prcomp(train_sub)
plot(pca$sdev^2/sum(pca$sdev^2) , pch = 19)
pca$sdev^2/sum(pca$sdev^2)
sum(pca$sdev^2/sum(pca$sdev^2)[1:4])
ra <- pca$sdev^2/sum(pca$sdev^2)
sum(ra[1:4])
sum(ra[1:5])
sum(ra)
?preProcess
preProcess(train_sub, method = "pca", pcaComp = 2)
preProcess(train_sub, method = "pca")
preProcess(train_sub, method = "pca", pcaComp = 9)
preProcess(train_sub, method = "pca", thresh = 90)
preProcess(train_sub, method = "pca", thresh = .9)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
train_sub <- training[,grep("^IL|diagnosis", names(training))]
names(train_sub)
preproc <- preProcess(train_sub, method = "pca", thresh = 0.8)
trainpc <- predict(preproc, train_sub)
train(train_sub$diagnosis ~ ., method = "glm", data = trainpc)
preproc <- preProcess(train_sub[, -1], method = "pca", thresh = 0.8)
trainpc <- predict(preproc, train_sub[, -1])
train(train_sub$diagnosis ~ ., method = "glm", data = trainpc)
names(train_sub)
train_sub[, -1]
names(train_sub[, -1])
names(train_sub)
preproc <- preProcess(train_sub[, -1], method = "pca", thresh = 0.8)
trainpc <- predict(preproc, train_sub[, -1])
train(train_sub$diagnosis ~ ., method = "glm", data = trainpc)
train(train_sub$diagnosis ~ ., method = "glm", data = trainpc)
trainpc
names(trainpc)
names(train_sub)
train(train_sub$diagnosis ~ ., method = "glm", data = trainpc)
train(train_sub$diagnosis ~ ., method = "glm", data = train_sub[,-1])
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
install.packages("kernlab")
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
preProc <- preProcess(log10(training[,-58]+1),method="pca",pcaComp=2)
trainPC <- predict(preProc,log10(training[,-58]+1))
modelFit <- train(training$type ~ .,method="glm",data=trainPC)
preProc <- preProcess(log10(training[,-58]+1),method="pca",pcaComp=2)
trainPC <- predict(preProc,log10(training[,-58]+1))
train(training$type ~ .,method="glm",data=trainPC)
train(training$type ~ .,data=trainPC,method="glm")
train(training$type ~ trainPC,method="glm")
train(training$type~.,data=trainPC,method="glm")
names(training)[58]
names(trainPC)
?train
q()
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
train_sub <- training[,grep("^IL|diagnosis", names(training))]
preproc <- preProcess(train_sub[,-1], method = "pca", thresh = 0.8)
trainpc <- predict(preproc, train_sub[,-1])
modelfit <- train(train_sub$diagnosis ~ ., method = "glm", data = trainpc)
trainpc1 <- cbind(train_sub$diagnosis, trainpc)
names(trainpc1)
head(trainpc1)
modelfit <- train(train_sub$diagnosis ~ ., method = "glm", data = trainpc1)
modelfit <- train(train_sub$diagnosis ~ ., method = "glm", data = trainpc)
training$diagnosis
modelfit <- train(I(1*train_sub$diagnosis) ~ ., method = "glm", data = trainpc)
modelfit <- train(1*I(train_sub$diagnosis == Impaired) ~ ., method = "glm", data = trainpc)
modelfit <- train(1*I(train_sub$diagnosis == "Impaired") ~ ., method = "glm", data = trainpc)
levels(training$diagnosis)
levels(train_sub$diagnosis)
head(training)
head(train_sub)
summary(train_sub)
head(trainpc)
summary(train_pc)
summary(trainpc)
modelfit <- train(train_sub$diagnosis ~ ., method = "glm", preProcess = "pca", data = trainpc)
modelfit <- train(train_sub$diagnosis ~ ., method = "glm", preProcess = "pca", data = train_sub)
q()
library(ElemStatLearn); data(ozone,package="ElemStatLearn")
# reorder rows based on ozone variable
ozone <- ozone[order(ozone$ozone),]
# create empty matrix
ll <- matrix(NA,nrow=10,ncol=155)
install.packages("ElemStatLearn")
library(ElemStatLearn); data(ozone,package="ElemStatLearn")
# reorder rows based on ozone variable
ozone <- ozone[order(ozone$ozone),]
# create empty matrix
ll <- matrix(NA,nrow=10,ncol=155)
sample(1:dim(ozone)[1],replace=T)
ss <-sample(1:dim(ozone)[1],replace=T)
length(ss)
dim(ozone)
head(ozone)
# load data
library(ElemStatLearn); data(ozone,package="ElemStatLearn")
# reorder rows based on ozone variable
ozone <- ozone[order(ozone$ozone),]
# create empty matrix
ll <- matrix(NA,nrow=10,ncol=155)
# iterate 10 times
for(i in 1:10){
# create sample from data with replacement
ss <- sample(1:dim(ozone)[1],replace=T)
# draw sample from the dataa and reorder rows based on ozone
ozone0 <- ozone[ss,]; ozone0 <- ozone0[order(ozone0$ozone),]
# fit loess function through data (similar to spline)
loess0 <- loess(temperature ~ ozone,data=ozone0,span=0.2)
# prediction from loess curve for the same values each time
ll[i,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
# plot the data points
plot(ozone$ozone,ozone$temperature,pch=19,cex=0.5)
# plot each prediction model
for(i in 1:10){lines(1:155,ll[i,],col="grey",lwd=2)}
# plot the average in red
lines(1:155,apply(ll,2,mean),col="red",lwd=2)
q()
install.packages("shiny")
library(shiny)
q()
setwd("~/R/DataScienceJHU/Developing Data Products/Course Project/cp1")
library(leaflet)
hopkinsIcon <- makeIcon(
iconUrl = "http://brand.jhu.edu/content/uploads/2014/06/university.shield.small_.blue_.png",
iconWidth = 31*215/230, iconHeight = 31,
iconAnchorX = 31*215/230/2, iconAnchorY = 16
)
hopkinsLatLong <- data.frame(
lat = c(39.2973166, 39.3288851, 39.2906617),
lng = c(-76.5929798, -76.6206598, -76.5469683))
hopkinsLatLong %>%
leaflet() %>%
addTiles() %>%
addMarkers(icon = hopkinsIcon)
library(maps)
mapStates = map("state", fill = TRUE, plot = FALSE)
leaflet(data = mapStates) %>% addTiles() %>%
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE)
?map
m = leaflet() %>% addTiles()
df = data.frame(
lat = rnorm(100),
lng = rnorm(100),
size = runif(100, 5, 20),
color = sample(colors(), 100)
)
m = leaflet(df) %>% addTiles()
m %>% addCircleMarkers(radius = ~size, color = ~color, fill = FALSE)
m %>% addCircleMarkers(radius = runif(100, 4, 10), color = c('red'))
Sr1 = Polygon(cbind(c(2, 4, 4, 1, 2), c(2, 3, 5, 4, 2)))
Sr2 = Polygon(cbind(c(5, 4, 2, 5), c(2, 3, 2, 2)))
Sr3 = Polygon(cbind(c(4, 4, 5, 10, 4), c(5, 3, 2, 5, 5)))
Sr4 = Polygon(cbind(c(5, 6, 6, 5, 5), c(4, 4, 3, 3, 4)), hole = TRUE)
Srs1 = Polygons(list(Sr1), "s1")
Srs2 = Polygons(list(Sr2), "s2")
Srs3 = Polygons(list(Sr4, Sr3), "s3/4")
SpP = SpatialPolygons(list(Srs1, Srs2, Srs3), 1:3)
leaflet(height = "300px") %>% addPolygons(data = SpP)
library(sp)
Sr1 = Polygon(cbind(c(2, 4, 4, 1, 2), c(2, 3, 5, 4, 2)))
Sr2 = Polygon(cbind(c(5, 4, 2, 5), c(2, 3, 2, 2)))
Sr3 = Polygon(cbind(c(4, 4, 5, 10, 4), c(5, 3, 2, 5, 5)))
Sr4 = Polygon(cbind(c(5, 6, 6, 5, 5), c(4, 4, 3, 3, 4)), hole = TRUE)
Srs1 = Polygons(list(Sr1), "s1")
Srs2 = Polygons(list(Sr2), "s2")
Srs3 = Polygons(list(Sr4, Sr3), "s3/4")
SpP = SpatialPolygons(list(Srs1, Srs2, Srs3), 1:3)
leaflet(height = "300px") %>% addPolygons(data = SpP)
library(maps)
mapStates = map("world", fill = TRUE, plot = FALSE)
leaflet(data = mapStates) %>% addTiles() %>%
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE)
?map
library(maps)
mapStates = map("county", fill = TRUE, plot = FALSE)
leaflet(data = mapStates) %>% addTiles() %>%
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE)
?map
library(maps)
mapStates = map("state", fill = TRUE, plot = FALSE, namesonly = TRUE)
leaflet(data = mapStates) %>% addTiles() %>%
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE)
library(maps)
mapStates = map("usa", fill = TRUE, plot = FALSE, namesonly = TRUE)
leaflet(data = mapStates) %>% addTiles() %>%
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE)
library(maps)
mapStates = map("usa", fill = TRUE, plot = FALSE)
leaflet(data = mapStates) %>% addTiles() %>%
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE)
?map
library(maps)
mapStates = map("world", fill = TRUE, plot = FALSE)
leaflet(data = mapStates) %>% addTiles() %>%
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE)
library(rMaps)
L2 <- Leaflet$new()
L2$setView(c(29.7632836,  -95.3632715), 10)
L2$tileLayer(provider = "MapQuestOpen.OSM")
L2
install.packages("rMaps")
library(leaflet)
L2 <- leaflet()
L2$setView(c(29.7632836,  -95.3632715), 10)
L2$tileLayer(provider = "MapQuestOpen.OSM")
L2
library(maps)
mapStates = map("state", fill = TRUE, plot = FALSE)
leaflet(data = mapStates) %>% addTiles() %>%
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE)
list.files()
wc <- read.csv("world_cities.csv")
names(wc)
head(wc)
head(wc$country=="USA")
levels(wc$country)
head(wc$country=="United States of America")
head(wc[wc$country=="United States of America",])
scc <- read.csv("list-state-capitals-us.csv")
head(scc)
scc <- read.csv("list-state-capitals-us.csv", skip = 1)
scc <- read.csv("list-state-capitals-us.csv")
head(scc, 10)
head(scc, 20)
head(scc, 20:30)
head(scc, 30)
scc <- read.csv("list-state-capitals-us.csv", skip = 1)
?read.csv
scc <- read.csv("list-state-capitals-us.csv")
scc <- read.csv("list-state-capitals-us.csv")
scc <- read.csv("list-state-capitals-us.csv")
names(scc   )
names(scc)
head(scc, 10)
scc <- read.csv("list-state-capitals-us.csv")
head(scc, 10)
wc <- read.csv("world_cities.csv")
head(wc)
wc_us <- wc[wc$country == "United State of America",]
wc_us
levels(wc$country)
wc_us <- wc[wc$country == "United States of America",]
wc_us
head(scc, 10)
state_capitals <- read.csv("list-state-capitals-us.csv")
state_capitals %>% select(c(2,5))
library(dplyr)
state_capitals <- read.csv("list-state-capitals-us.csv")
state_capitals %>% select(c(2,5))
state_capitals <- read.csv("list-state-capitals-us.csv")
state_capitals[,1:5]
state_capitals <- read.csv("list-state-capitals-us.csv")
state_capitals %>% select(c(2,5))
head(wc_us)
world_cities <- read.csv("world_cities.csv")
usa_cities <- filter(world_cities, country == "United States of America") %>% select(city, lat, lng, province)
usa_cities
state_capitals <- read.csv("list-state-capitals-us.csv")
state_capitals %>% select(c(2,5))
state_capitals <- read.csv("list-state-capitals-us.csv")
state_capitals %>% select(c(2,5))
world_cities <- read.csv("world_cities.csv")
usa_cities <- filter(world_cities, country == "United States of America")%>%
select(city, lat, lng, province) %>%
filter(city == state_capitals$Capital)
state_capitals <- read.csv("list-state-capitals-us.csv")
state_capitals %>% select(c(2,5))
world_cities <- read.csv("world_cities.csv")
usa_cities <- filter(world_cities, country == "United States of America")%>%
select(city, lat, lng, province) %>%
filter(city %in% state_capitals$Capital)
usa_cities
state_capitals <- read.csv("list-state-capitals-us.csv")
state_capitals %>% select(c(2,5))
world_cities <- read.csv("world_cities.csv")
usa_cities <- filter(world_cities, country == "United States of America")%>%
select(city, lat, lng, province) %>%
filter(c(province, city) %in% state_capitals)
state_capitals <- read.csv("list-state-capitals-us.csv")
state_capitals %>% select(c(2,5))
world_cities <- read.csv("world_cities.csv")
usa_cities <- filter(world_cities, country == "United States of America")%>%
select(city, lat, lng, province) %>%
filter(city %in% state_capitals$Capital & province %in% state_capitals$State)
usa_cities
state_capitals <- read.csv("list-state-capitals-us.csv")
state_capitals %>% select(c(2,5)) %>% mutate(capital_state = paste(Capital, State, sep = ","))
state_capitals <- read.csv("list-state-capitals-us.csv")
state_capitals %>% select(c(2,5)) %>% mutate(Capital_State = paste(Capital, State, sep = ","))
world_cities <- read.csv("world_cities.csv")
usa_cities <- filter(world_cities, country == "United States of America")%>%
select(city, lat, lng, province) %>%
mutate(city_province = paste(city, province, sep = ",")) %>%
filter(city_province %in% state_capitals$Capital_State)
usa_cities
state_capitals
state_capitals <- read.csv("list-state-capitals-us.csv")
state_capitals %>% select(c(2,5)) %>% mutate(Capital_State = paste(Capital, State, sep = ","))
state_capitals
world_capitals <- read.csv("list-state-capitals-us.csv")
state_capitals <- world_capitals %>%
select(c(2,5)) %>% mutate(Capital_State = paste(Capital, State, sep = ","))
state_capitals
world_cities <- read.csv("world_cities.csv")
usa_cities <- filter(world_cities, country == "United States of America")%>%
select(city, lat, lng, province) %>%
mutate(city_province = paste(city, province, sep = ",")) %>%
filter(city_province %in% state_capitals$Capital_State)
usa_cities
usa_cities <- filter(world_cities, country == "United States of America")%>%
select(city, lat, lng, province) %>%
mutate(city_province = paste(city, province, sep = ",")) %>%
filter(city_province %in% state_capitals$Capital_State) %>%
select(city_province, lat, lng)
usa_cities
names(world_capitals)
names(world_cities)
head(world_cities)
world_capitals <- read.csv("list-state-capitals-us.csv")
state_capitals <- world_capitals %>%
select(c(2,5)) %>% mutate(Capital_State = paste(Capital, State, sep = ","))
world_cities <- read.csv("world_cities.csv")
usa_cities <- filter(world_cities, country == "United States of America")%>%
select(city, lat, lng, pop, province) %>%
mutate(city_province = paste(city, province, sep = ",")) %>%
filter(city_province %in% state_capitals$Capital_State) %>%
select(city_province, lat, lng, pop)
usa_cities
?addCircles
?addCircles
?addCircleMarkers
line()
line
?line
mean
plot
print
getS3method("mean", "default")
library(methods)
setClass("polygon",
representation(x = "numeric",
y = "numeric"))
setMethod("plot", "polygon",
function(x, y, ...) {
plot(x@x, x@y, type = "n", ...)
xp <- c(x@x, x@x[1])
yp <- c(x@y, x@y[1])
lines(xp, yp)
})
showMethods("plot")
p <- new("polygon", x = c(1, 2, 3, 4), y = c(1, 2, 3, 1))
plot(p)
p <- new("polygon", x = c(1, 2, 3, 4, 5), y = c(1, 2, 3, 1, 4))
plot(p)
p <- new("polygon", x = c(1, 2, 3, 4, 5), y = c(1, 2, 3, 4, 1))
plot(p)
p <- new("polygon", x = c(1, 3, 4, 5, 6), y = c(1, 2, 3, 4, 1))
plot(p)
p <- new("polygon", x = c(1, 3, 4, 5, 6), y = c(1, 2, 4, 4, 1))
plot(p)
p <- new("polygon", x = c(1, 3, 4, 5, 6), y = c(1, 2, 4, 4, 1))
plot(p, pch = 20)
?lines
plot("n")
plot(1:6, 1:6, "n")
lines(c(1,1), c(2,3))
colSums
dgamma
predict
show
lm
mean
setwd("~/R/DataScienceJHU/Developing Data Products")
setwd("~/R/DataScienceJHU/Developing Data Products/DDPQuiz3")
list.dirs()
show
predict
q()
setwd("~/R/DataScienceJHU/Developing Data Products/Course Project/cp3/MacDonaldMap")
library(sp)
?spDistsN1
shiny::runApp()
runApp()
runApp()
runApp()
[3]: https://github.com/bolaik/ShinyMapMacDonald
runApp()
[1]: https://gist.github.com/erichurst/7882666
runApp()
runApp()
runApp()
q()
